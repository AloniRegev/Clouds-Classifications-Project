{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AloniRegev/Defense-Against-Adversarial-Examples-in-NN/blob/Regev-dev/DL_project_adversary_attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XA7jz320MgQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmu0PDC0zBqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f780842e-c82b-4714-b7a1-5a01c87a9e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available. Training on GPU\n",
            "Files already downloaded and verified\n",
            " trainset: Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomCrop(size=(32, 32), padding=4)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
            "           )\n",
            "Files already downloaded and verified\n",
            "train set len 40000\n",
            "validation set len 10000\n",
            "test set len 10000\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          18,496\n",
            "              ReLU-5           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-6           [-1, 64, 16, 16]               0\n",
            "            Conv2d-7          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-8          [-1, 128, 16, 16]             256\n",
            "              ReLU-9          [-1, 128, 16, 16]               0\n",
            "           Conv2d-10          [-1, 128, 16, 16]         147,584\n",
            "             ReLU-11          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-12            [-1, 128, 8, 8]               0\n",
            "        Dropout2d-13            [-1, 128, 8, 8]               0\n",
            "           Conv2d-14            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-15            [-1, 256, 8, 8]             512\n",
            "             ReLU-16            [-1, 256, 8, 8]               0\n",
            "           Conv2d-17            [-1, 256, 8, 8]         590,080\n",
            "             ReLU-18            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-19            [-1, 256, 4, 4]               0\n",
            "          Dropout-20            [-1, 256, 4, 4]               0\n",
            "           Conv2d-21            [-1, 512, 1, 1]       2,097,664\n",
            "             ReLU-22            [-1, 512, 1, 1]               0\n",
            "           Conv2d-23            [-1, 256, 1, 1]         131,328\n",
            "             ReLU-24            [-1, 256, 1, 1]               0\n",
            "          Dropout-25            [-1, 256, 1, 1]               0\n",
            "           Conv2d-26             [-1, 64, 1, 1]          16,448\n",
            "             ReLU-27             [-1, 64, 1, 1]               0\n",
            "           Conv2d-28             [-1, 10, 1, 1]             650\n",
            "================================================================\n",
            "Total params: 3,373,002\n",
            "Trainable params: 3,373,002\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.95\n",
            "Params size (MB): 12.87\n",
            "Estimated Total Size (MB): 16.83\n",
            "----------------------------------------------------------------\n",
            "CNN_model(\n",
            "  (feature_extractor): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05, inplace=False)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.1, inplace=False)\n",
            "    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1))\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(64, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Finished Training model\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "base model for CIFAR-10 performence:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: in test 0.8890999555587769\n",
            "Converting batch no. 0 in 157\n",
            "ther are 384 misclassifications in 1152 sempels.\n",
            "ther are 384 misclassifications in 1152 sempels.\n",
            "Accuracy: in test of deepfool 0.6666666666666667\n",
            "\n",
            "\n",
            "deepfool attack performence:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: in test 0.0598958358168602\n",
            "\n",
            "\n",
            "starting adversarial train loader\n",
            "\n",
            "\n",
            "Converting batch no. 0 in 625\n",
            "ther are 0 misclassifications in 0 sempels.\n",
            "\n",
            "\n",
            "starting adversarial val  loader\n",
            "\n",
            "\n",
            "Converting batch no. 0 in 157\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e89c49b4a660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0madver_trainLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalling_deepfool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nstarting adversarial val  loader\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m     \u001b[0madver_valLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalling_deepfool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;31m# model_adv_train = train_data(model, 100, 0.0001, loss_fn, adver_trainLoader, adver_valLoader, PATH_ADV_deepfool,feature_squeezing=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e89c49b4a660>\u001b[0m in \u001b[0;36mcalling_deepfool\u001b[0;34m(model, xLoader, accflag)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpert_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepfool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m             \u001b[0;31m# if label_orig != label.item():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[0;31m# print(f'label_orig: {label_orig}, label: {label}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e89c49b4a660>\u001b[0m in \u001b[0;36mdeepfool\u001b[0;34m(image, model, num_classes, overshoot, max_iter)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# finding hyperplane which gives smallest difference between all classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# print('before backward 2')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0mcur_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch._C import NoneType\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch import optim\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data\n",
        "from torchsummary import summary\n",
        "\n",
        "import copy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    transform_train = transforms.Compose([\n",
        "        # agmentation below\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # regular normalization\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ])\n",
        "\n",
        "    # Normalize the test set same as training set without augmentation\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ])\n",
        "\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    print(f' trainset: {trainset}')\n",
        "    # print(f' trainset shape: {trainset.size()}')\n",
        "\n",
        "    ## script to find mean\n",
        "    # data = trainset.data / 255  # data is numpy array\n",
        "    #\n",
        "    # mean = data.mean(axis=(0, 1, 2))\n",
        "    # std = data.std(axis=(0, 1, 2))\n",
        "    # print(f\"Mean : {mean}   STD: {std}\")  # Mean : [0.491 0.482 0.446]   STD: [0.247 0.243 0.261]\n",
        "\n",
        "    cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True,\n",
        "                                     transform=transform_test)  # transform_test\n",
        "    cifar_trainset, cifar_valset = data.random_split(trainset, [int(len(trainset) * 0.8), int(len(\n",
        "        trainset) * 0.2)])  # split the trainset to trainset and validation set in 80%-20% retio\n",
        "\n",
        "    print('train set len', len(cifar_trainset))\n",
        "    print('validation set len', len(cifar_valset))\n",
        "    print('test set len', len(cifar_testset))\n",
        "\n",
        "    number_workers = 0\n",
        "    if device == torch.device('cuda'):\n",
        "        number_workers = 2\n",
        "    train_loader = data.DataLoader(cifar_trainset, shuffle=True, batch_size=64, num_workers=number_workers)\n",
        "    val_loader = data.DataLoader(cifar_valset, shuffle=False, batch_size=64, num_workers=number_workers)\n",
        "    test_loader = data.DataLoader(cifar_testset, shuffle=False, batch_size=64, num_workers=number_workers)\n",
        "\n",
        "    test_for_adv = data.DataLoader(cifar_testset, shuffle=False, batch_size=1)\n",
        "    train_for_adv = data.DataLoader(cifar_trainset, shuffle=True, batch_size=1)\n",
        "    return train_loader, val_loader, test_loader, test_for_adv, train_for_adv\n",
        "\n",
        "\n",
        "# model3:  with dropout, with batch, without fc layers\n",
        "\n",
        "\n",
        "class CNN_model(nn.Module):  # TODO: fix so I get correct dimensions of output\n",
        "    def __init__(self):\n",
        "        super(CNN_model, self).__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=1),\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # conv layers\n",
        "        features = self.feature_extractor(x)\n",
        "        # print(\"features shape:\", features.shape)\n",
        "\n",
        "        # final non fully connected\n",
        "        class_scores = self.classifier(features)\n",
        "        # print(\"class_scores shape:\", class_scores.shape)\n",
        "        class_scores = torch.reshape(class_scores, (class_scores.size(dim=0), class_scores.size(dim=1)))\n",
        "        # print(\"class_scores shape:\", class_scores.shape)\n",
        "\n",
        "        return class_scores\n",
        "\n",
        "\n",
        "# Train\n",
        "def train_data(model, epochs, learning_rate, loss_function, train_loader, valid_loader, PATH, feature_squeezing=False,\n",
        "               patience=4):\n",
        "    loss_arr = []\n",
        "    avg_train_loss_arr, avg_val_loss_arr = [], []\n",
        "    train_acc_arr, val_acc_arr = [], []\n",
        "    # Early stopping  parameters\n",
        "    last_loss = 100  # initializing max loss as high unreachable value\n",
        "    trigger_times = 0\n",
        "    total, correct = 0.0, 0.0\n",
        "    \n",
        "\n",
        "    # for i in range(5):\n",
        "    #   data_iter = iter(filtered_images)\n",
        "    #   pert_image_numpy = next(data_iter)[i].cpu().detach().squeeze().numpy()\n",
        "    #   print(pert_image_numpy.shape)\n",
        "    #   plt.figure()\n",
        "    #   plt.imshow(pert_image_numpy.transpose(1, 2, 0))\n",
        "    #   #plt.title(label_pert)\n",
        "    #   plt.show()\n",
        "\n",
        "    # images = next(data_iter)\n",
        "    # print(type(images))\n",
        "    # print(images.shape)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00012)\n",
        "\n",
        "    # dataiter = iter(train_loader)\n",
        "    # images, labels = dataiter.next()\n",
        "    # print(type(images))\n",
        "    # print(images.shape)\n",
        "    # print(labels.shape)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # defining we're training so can use dropout, batch norm\n",
        "        # if len(filtered_images) > 0:\n",
        "        #     feature_squeezing = True\n",
        "        #     data_iter = iter(filtered_images)\n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "            if device == torch.device('cuda'):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward and backward propagation\n",
        "            if feature_squeezing:\n",
        "              batch_cur = []\n",
        "              for j in range(len(inputs)):\n",
        "                  cur_img = ndimage.median_filter(inputs[j].cpu().detach(), size=(2, 2, 2), origin=-1)  # mode is reflect by default  # sliding window size is: (2,2), shifted to image right\n",
        "                  batch_cur.append(cur_img)\n",
        "                  #squeezed_images.append(torch.tensor(np.array(batch_cur)))\n",
        "              outputs = model(torch.tensor(np.array(batch_cur)).to(device))\n",
        "              #outputs = model(next(data_iter).to(device))\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss_arr.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Show progress\n",
        "            if i % 100 == 0 or i == len(train_loader):\n",
        "                # print('[{}/{}, {}/{}] loss: {:.8}'.format(epoch, epochs, i, len(train_loader), loss.item()))\n",
        "                print(\"Iteration: {0} | Loss: {1} | index {2} \".format(epoch, loss.item(), i))\n",
        "\n",
        "            total += inputs.shape[0]\n",
        "            predictions = torch.argmax(outputs.data, dim=1)\n",
        "            correct += torch.sum(predictions == labels).type(torch.float32)\n",
        "\n",
        "        # print(\"total is: {0}, len(train_loader): {1}, correct pred num is: {2}\".format(total, len(train_loader), correct))\n",
        "        train_acc = (correct / total).item()\n",
        "        print('Accuracy: in train', train_acc)\n",
        "        train_acc_arr.append(train_acc)\n",
        "\n",
        "        plot_graph(loss_arr, \"generic network training loss\")\n",
        "        avg_train_loss_arr.append(np.mean(loss_arr))\n",
        "        # Early stopping\n",
        "        current_loss, avg_val_loss, val_acc = validation_data(model, valid_loader)\n",
        "        print('The Current Loss by validation data:', current_loss)\n",
        "        avg_val_loss_arr.append(avg_val_loss.item())\n",
        "        val_acc_arr.append(val_acc)\n",
        "\n",
        "        if current_loss > last_loss:\n",
        "            trigger_times += 1\n",
        "            # print('Trigger Times:', trigger_times)\n",
        "\n",
        "            if trigger_times >= patience:\n",
        "                print('Early stopping!\\nStart to test process.')\n",
        "                break  # exit loop, print data\n",
        "\n",
        "        else:\n",
        "            # print('trigger times did not increase:' , trigger_times)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            trigger_times = 0\n",
        "\n",
        "        last_loss = current_loss\n",
        "\n",
        "    model.load_state_dict(torch.load(PATH))\n",
        "    plot_graph(loss_arr, \"generic network training loss\")\n",
        "\n",
        "    title = \"avg train loss vs avg validation loss\"\n",
        "    plot_two_graphs(avg_train_loss_arr, avg_val_loss_arr, title, 'train loss', 'val loss', 'loss',\n",
        "                    'avg_train_loss_vs_avg_validation_loss')\n",
        "\n",
        "    title = \"avg train acc vs avg validation acc\"\n",
        "    plot_two_graphs(train_acc_arr, val_acc_arr, title, 'train accuracy', 'validation accuracy', 'accuracy',\n",
        "                    'avg_train_acc_vs_avg_validation_acc')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def plot_graph(list, title):\n",
        "    plt.plot(list)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def plot_two_graphs(list1, list2, title, label1, label2, y_label, plot_path):\n",
        "    plt.plot(list1, label=label1)\n",
        "    # Plot another line on the same chart/graph\n",
        "    plt.plot(list2, label=label2)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel(y_label)\n",
        "    # plt.savefig('./outputs/'+plot_path+'.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def validation_data(model, valid_loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_total = 0.0\n",
        "    loss_arr = []\n",
        "\n",
        "    # iterate over test data\n",
        "    with torch.no_grad():  # disable gradients because we only run on test data\n",
        "        for (data, labels) in valid_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device == torch.device('cuda'):\n",
        "                data, labels = data.cuda(), labels.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss_valid = loss_fn(output, labels)\n",
        "            loss_arr.append(loss_valid.item())\n",
        "            loss_total += loss_valid.item()\n",
        "\n",
        "            total += data.shape[0]\n",
        "            predictions = torch.argmax(output.data, dim=1)\n",
        "            correct += torch.sum(predictions == labels).type(torch.float32)\n",
        "\n",
        "    # plot_graph(loss_arr, \"generic network valid loss\")\n",
        "    acc = (correct / total)\n",
        "    print('Accuracy: in validation', acc.item())\n",
        "\n",
        "    return (loss_total / len(valid_loader)), np.mean(loss_arr), acc.item()\n",
        "\n",
        "\n",
        "def test_data(model, test_loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_arr = []\n",
        "\n",
        "    # iterate over test data\n",
        "    with torch.no_grad():  # disable gradients because we only run on test data\n",
        "        for (data, labels) in test_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device == torch.device('cuda'):\n",
        "                data, labels = data.cuda(), labels.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss_test = loss_fn(output, labels)\n",
        "            loss_arr.append(loss_test.item())\n",
        "\n",
        "            total += data.shape[0]\n",
        "            predictions = torch.argmax(output.data, dim=1)\n",
        "            correct += torch.sum(predictions == labels).type(torch.float32)\n",
        "\n",
        "    plot_graph(loss_arr, \"generic network test loss\")\n",
        "\n",
        "    print('Accuracy: in test', (correct / total).item())\n",
        "\n",
        "\n",
        "def deepfool(image, model, num_classes=10, overshoot=0.02, max_iter=10):  # overshoot prevents vanishing updates\n",
        "    model.eval()\n",
        "    # print('in deepfool before first forward')\n",
        "\n",
        "    image.requires_grad = True\n",
        "    out_orig = model.forward(image.to(device))\n",
        "\n",
        "    temp = np.array(out_orig.cpu().detach().numpy())  # getting image prediction labels\n",
        "    labels = temp.flatten().argsort()[::-1]  # labels indexes from low to high\n",
        "    # print(labels)\n",
        "    # print('after first')\n",
        "\n",
        "    labels = labels[0:num_classes]  # starting with label with highest prediction\n",
        "    label = labels[0]\n",
        "\n",
        "    input_shape = image.detach().shape\n",
        "    pert_image = copy.deepcopy(image)\n",
        "    w = np.zeros(input_shape)\n",
        "    pert_tot = np.zeros(input_shape)\n",
        "    ctr = 0\n",
        "\n",
        "    x = pert_image[None, :].clone().detach().requires_grad_(True).to(device)\n",
        "    x.retain_grad()\n",
        "    out = model.forward(x[0])\n",
        "    # print('after second forward')\n",
        "    label_cur = label\n",
        "\n",
        "    while label_cur == label and ctr < max_iter:  # and x.grad is not None\n",
        "\n",
        "        pert = np.inf\n",
        "        # print('before backward 1')\n",
        "        out[0, labels[0]].backward(\n",
        "            retain_graph=True)  # retain_graph for iterating through the graph after the first time\n",
        "        # print(x.grad)\n",
        "        grad_orig = x.grad.data.cpu().detach().numpy().copy()\n",
        "\n",
        "        for i in range(1, num_classes):  # finding hyperplane which gives smallest difference between all classes\n",
        "            # print('before backward 2')\n",
        "            out[0, labels[i]].backward(retain_graph=True)\n",
        "            cur_grad = x.grad.data.cpu().detach().numpy().copy()\n",
        "\n",
        "            w_cur = cur_grad - grad_orig\n",
        "            out_diff = (out[0, labels[i]] - out[0, labels[\n",
        "                0]]).data.cpu().detach().numpy()  # difference between prediction of original image and perturbed\n",
        "\n",
        "            # using formula to calculate current hyperplane\n",
        "            hyperplane_cur = abs(out_diff) / np.linalg.norm(w_cur.flatten())\n",
        "\n",
        "            # getting minimal change hyperplane\n",
        "            if hyperplane_cur < pert:\n",
        "                pert = hyperplane_cur\n",
        "                w = w_cur\n",
        "\n",
        "        # Added 1e-4 for numerical stability\n",
        "        pert_cur = (pert + 1e-4) * w / np.linalg.norm(w)\n",
        "        # calculating new perturbed image to updated image under min hyperplane such that her projection changed\n",
        "        pert_tot = np.float32(pert_tot + pert_cur)\n",
        "\n",
        "        pert_image = image.cpu().detach() + (1 + overshoot) * torch.from_numpy(pert_tot)\n",
        "\n",
        "        x = pert_image.clone().detach().requires_grad_(True).to(device)\n",
        "        x.retain_grad()\n",
        "        # print('before final forward')\n",
        "        out = model.forward(x[0])\n",
        "        label_cur = np.argmax(out.data.cpu().detach().numpy().flatten())  # label of pert image\n",
        "\n",
        "        ctr += 1\n",
        "\n",
        "    pert_tot = (1 + overshoot) * pert_tot\n",
        "\n",
        "    return pert_tot, ctr, label, label_cur, pert_image\n",
        "\n",
        "\n",
        "# def batched_deepfool(model, batch):\n",
        "#     sum_diff = 0\n",
        "#     adv_images = []\n",
        "#     for j in range(len(batch)):  # images one by one\n",
        "#         r, loop_i, label_orig, label_pert, pert_image = deepfool(batch[j].unsqueeze(0), model, max_iter=50)\n",
        "#         # if label_orig != label_pert:\n",
        "#         #     sum_diff += 1\n",
        "#         adv_images.append(pert_image.detach().squeeze().to(device))\n",
        "#     # print(pert_image.detach().squeeze().to(device).shape)\n",
        "#     # print(torch.stack(adv_images).shape)\n",
        "#     final = torch.stack(adv_images)\n",
        "#     return \n",
        "    \n",
        "\n",
        "def xLoader_deepfool(model, xLoader):\n",
        "    sum_diff = 0\n",
        "    newLoader=[]\n",
        "    loaderSize=len(xLoader)\n",
        "    for i,batch in enumerate(xLoader):\n",
        "        misclassified = []\n",
        "        if i % 25 ==0:\n",
        "          print(\"Converting batch no. {} in {}\".format(i,loaderSize))\n",
        "        # print(batch)\n",
        "        images, labels = batch[0].to(device), batch[1].to(device)\n",
        "        for image in images:\n",
        "            r, loop_i, label_orig, label_pert, pert_image = deepfool(image.unsqueeze(0), model, max_iter=50)\n",
        "            # if label_orig != label.item():\n",
        "                # print(f'label_orig: {label_orig}, label: {label}')\n",
        "            misclassified.append(pert_image.detach().squeeze().to(device))\n",
        "        \n",
        "        newLoader.append((torch.stack(misclassified),labels))\n",
        "    return newLoader\n",
        "\n",
        "\n",
        "# def batched_deepfool_train(model, train_loader):  # applying deepfool on each batch and whole train loader\n",
        "#     adv_images = []\n",
        "#     for i, (batch, labels) in enumerate(train_loader, 0):\n",
        "#         batch_cur = []\n",
        "#         for j in range(len(batch)):\n",
        "#             r, loop_i, label_orig, label_pert, pert_image = deepfool(batch[j].unsqueeze(0), model, max_iter=50)\n",
        "#             batch_cur.append(pert_image.detach().squeeze().to(device))\n",
        "#         adv_images.append(torch.stack(batch_cur))\n",
        "#     print(pert_image.detach().squeeze().to(device).shape)\n",
        "#     print(torch.stack(adv_images).shape)\n",
        "#     final = torch.stack(adv_images)\n",
        "#     torch.save(final, 'final_adv_images.pt')\n",
        "#     return final\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "# def calling_deepfool(model, xLoader):\n",
        "#     sum_diff = 0\n",
        "#     misclassified = []\n",
        "#     loaderSize=len(xLoader)\n",
        "#     for i, (image, label) in enumerate(xLoader):\n",
        "#         if device == torch.device('cuda'):\n",
        "#             image, label = image.cuda(), label.cuda()\n",
        "#         r, loop_i, label_orig, label_pert, pert_image = deepfool(image, model, max_iter=50)\n",
        "#         # if label_orig != label.item():\n",
        "#           # print(f'{i}. label_orig: {label_orig}, label: {label.item()}')\n",
        "\n",
        "#         if i % 500 ==0:\n",
        "#            print(\"Converting batch no. {} in {}\".format(i,loaderSize))\n",
        "\n",
        "\n",
        "#         misclassified.append((pert_image.detach().squeeze(0).to(device), label))\n",
        "#         if label_orig != label_pert:\n",
        "#             sum_diff += 1\n",
        "#         # if sum_diff ==200:\n",
        "#         #     print(f'index is: {i}, sum_diff is: {sum_diff}')\n",
        "#         #     break\n",
        "#     print(f'index is: {i}, sum_diff is: {sum_diff}')\n",
        "#     acc = 1 - (sum_diff / (i + 1))\n",
        "#     print('Accuracy: in test of deepfool', acc)  # accuracy on perturbed images\n",
        "\n",
        "#     # pert_image_numpy = pert_image.detach().squeeze().numpy()\n",
        "#     # print(pert_image_numpy.shape)\n",
        "#     # plt.figure()\n",
        "#     # plt.imshow((pert_image_numpy * 255).astype(np.uint8).transpose(1, 2, 0))\n",
        "#     # plt.title(label_pert)\n",
        "#     # plt.show()\n",
        "\n",
        "#     # plt.figure()\n",
        "#     # origin = image.cpu().detach().squeeze().numpy()\n",
        "#     # plt.imshow((origin * 255).astype(np.uint8).transpose(1, 2, 0))\n",
        "#     # plt.title(label.item())\n",
        "#     # plt.show()\n",
        "\n",
        "#     # r_new = r.squeeze().numpy()\n",
        "\n",
        "#     # plt.figure()\n",
        "#     # plt.imshow((r_new * 255).astype(np.uint8).transpose(1, 2, 0))\n",
        "#     # plt.show()\n",
        "\n",
        "#     return misclassified\n",
        "\n",
        "def calling_deepfool(model, xLoader, accflag=False):\n",
        "    sum_diff = 0\n",
        "    newLoader=[]\n",
        "    loaderSize=len(xLoader)\n",
        "    total=0\n",
        "    for i,batch in enumerate(xLoader):\n",
        "        misclassified = []\n",
        "        if i % 25 ==0:\n",
        "          print(\"Converting batch no. {} in {}\".format(i,loaderSize))\n",
        "        # print(batch)\n",
        "        images, labels = batch[0].to(device), batch[1].to(device)\n",
        "        for image in images:\n",
        "            r, loop_i, label_orig, label_pert, pert_image = deepfool(image.unsqueeze(0), model, max_iter=50)\n",
        "            # if label_orig != label.item():\n",
        "                # print(f'label_orig: {label_orig}, label: {label}')\n",
        "            misclassified.append(pert_image.detach().squeeze().to(device))\n",
        "            \n",
        "            if accflag:\n",
        "              total += image.shape[0]\n",
        "              if label_orig != label_pert:\n",
        "                sum_diff += 1\n",
        "            \n",
        "        newLoader.append((torch.stack(misclassified),labels))\n",
        "        \n",
        "        # if i == 5:\n",
        "        #   print(f'ther are {sum_diff} misclassifications in {total} sempels.')\n",
        "        #   break\n",
        "    if accflag:\n",
        "      print(f'ther are {sum_diff} misclassifications in {total} sempels.')\n",
        "      acc = 1 - (sum_diff / total)\n",
        "      print('Accuracy: in test of deepfool', acc)  # accuracy on perturbed images\n",
        "\n",
        "      # pert_image_numpy = pert_image.detach().squeeze().numpy()\n",
        "      # print(pert_image_numpy.shape)\n",
        "      # plt.figure()\n",
        "      # plt.imshow((pert_image_numpy * 255).astype(np.uint8).transpose(1, 2, 0))\n",
        "      # plt.title(label_pert)\n",
        "      # plt.show()\n",
        "\n",
        "      # plt.figure()\n",
        "      # origin = image.cpu().detach().squeeze().numpy()\n",
        "      # plt.imshow((origin * 255).astype(np.uint8).transpose(1, 2, 0))\n",
        "      # plt.title(label.item())\n",
        "      # plt.show()\n",
        "\n",
        "      # r_new = r.squeeze().numpy()\n",
        "\n",
        "      # plt.figure()\n",
        "      # plt.imshow((r_new * 255).astype(np.uint8).transpose(1, 2, 0))\n",
        "      # plt.show()\n",
        "\n",
        "    return newLoader\n",
        "\n",
        "\n",
        "def adversarial_train(model, epochs, learning_rate, loss_function, train_loader, valid_loader,  PATH, adv_images=[]):\n",
        "    loss_arr = []\n",
        "    loss_clean_data = []\n",
        "    loss_pert_data = []\n",
        "    acc_clean_data = []\n",
        "    acc_pert_data = []\n",
        "\n",
        "    avg_train_loss_arr = []\n",
        "    avg_loss_clean_data = []\n",
        "    avg_loss_pert_data = []\n",
        "\n",
        "    val_loss = []\n",
        "    val_acc = []\n",
        "    total_train_acc = []\n",
        "    # # Early stopping  parameters\n",
        "    # last_loss = 100  # initializing max loss as high unreachable value\n",
        "    # trigger_times = 0\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00012)\n",
        "    total, correct = 0.0, 0.0\n",
        "    total_adv, correct_adv = 0.0, 0.0\n",
        "    step = 0\n",
        "    # breakstep = 0\n",
        "    for epoch in range(epochs):\n",
        "        if len(adv_images) ==0:\n",
        "            fgsm_attack = True\n",
        "\n",
        "            eps = 0.1\n",
        "        else:\n",
        "            itr = iter(adv_images)\n",
        "        model.train()  # defining we're training so can use dropout, batch norm\n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "            if device == torch.device('cuda'):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward and backward propagation\n",
        "            inputs.requires_grad_(True).retain_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss_arr.append(loss.item())\n",
        "            loss_clean_data.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            predictions = torch.argmax(outputs.data, dim=1)\n",
        "            correct += torch.sum(predictions == labels).type(torch.float32)\n",
        "            total += train_loader.batch_size\n",
        "\n",
        "            # Adversarial Training\n",
        "\n",
        "            if fgsm_attack:\n",
        "                grad = inputs.grad.data\n",
        "                perturbed_x = CreateAttack(inputs, eps, grad)\n",
        "                # Zero the gradients\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(perturbed_x.to(device))\n",
        "\n",
        "            else:\n",
        "                # adv_images = batched_deepfool(model, inputs)\n",
        "                # adv_images[i] = adv_images[i].to(device)\n",
        "                cur_adv_image = next(itr)\n",
        "                optimizer.zero_grad()\n",
        "                # Forward and backward propagation\n",
        "                # pert_image = pert_image.clone().detach().squeeze(1).to(device)\n",
        "                outputs = model(cur_adv_image)\n",
        "            # outputs = model(adv_images)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss_arr.append(loss.item())\n",
        "            loss_pert_data.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            predictions = torch.argmax(outputs.data, dim=1)\n",
        "            correct_adv += torch.sum(predictions == labels).type(torch.float32)\n",
        "            total_adv += train_loader.batch_size\n",
        "\n",
        "            step += 1\n",
        "            if total % 500 == 0:\n",
        "                acc = float(correct) / total\n",
        "                print('[%s] Clean Training accuracy: %.2f%%' % (step, acc * 100))\n",
        "                accAdv = float(correct_adv) / total_adv\n",
        "                print('[%s] Adv Training accuracy: %.2f%%' % (step, accAdv * 100))\n",
        "\n",
        "        train_acc = (correct / total)\n",
        "        print('Accuracy clean data: in train', train_acc)\n",
        "        acc_clean_data.append(train_acc)\n",
        "\n",
        "        plot_graph(loss_arr, \"generic network training loss\")\n",
        "        avg_train_loss_arr.append(np.mean(loss_arr))\n",
        "\n",
        "        plot_graph(avg_loss_clean_data, \"clean data network training loss\")\n",
        "        avg_loss_clean_data.append(np.mean(loss_clean_data))\n",
        "\n",
        "        plot_graph(avg_loss_pert_data, \"pert data network training loss\")\n",
        "        avg_loss_pert_data.append(np.mean(loss_pert_data))\n",
        "\n",
        "        train_adv_acc = (correct_adv / total_adv)\n",
        "        print('Accuracy adv: in train', train_adv_acc)\n",
        "        acc_pert_data.append(train_adv_acc)\n",
        "\n",
        "        current_loss, avg_val_loss, curr_val_acc = validation_data(model, valid_loader)\n",
        "        print('The Current Loss by validation data:', current_loss)\n",
        "        val_loss.append(avg_val_loss)\n",
        "        val_acc.append(curr_val_acc)\n",
        "\n",
        "        total_acc = float(correct + correct_adv) / (total_adv + total)\n",
        "        total_train_acc.append(total_acc)\n",
        "\n",
        "    plot_graph(loss_arr, \"generic network training loss\")\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "    title = \"adversary train loss on clean data vs loss on perturbed data\"\n",
        "    plot_two_graphs(avg_loss_pert_data, avg_loss_clean_data, title, 'loss pert data', 'loss clean data','loss',\n",
        "                    'train_loss_clean_vs_pert')\n",
        "\n",
        "    title = \"accuracy on clean data vs accuracy on perturbed data\"\n",
        "    plot_two_graphs(acc_pert_data, acc_clean_data, title, 'pert data acc', 'clean data acc','accuracy',\n",
        "                    'acc_clean_vs_pert')\n",
        "\n",
        "    title = \"adversary train loss vs avg validation loss\"\n",
        "    plot_two_graphs(avg_train_loss_arr, avg_val_loss, title, 'train loss', 'val loss','loss',\n",
        "                    'adv_train_loss_vs_avg_validation_loss')\n",
        "\n",
        "    title = \"adversary train acc vs avg validation acc\"\n",
        "    plot_two_graphs(total_train_acc, val_acc, title, 'train accuracy', 'validation accuracy', 'accuracy',\n",
        "                    'adv_train_acc_vs_avg_validation_acc')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# def feature_squeezing2(train_loader):  # applying deepfool on each batch and whole train loader\n",
        "#     squeezed_images = []\n",
        "#     for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "#         batch_cur = []\n",
        "#         for j in range(len(inputs)):\n",
        "#             cur_img = ndimage.median_filter(inputs[j], size=(2, 2, 2), origin=-1)  # mode is reflect by default\n",
        "#             # sliding window size is: (2,2), shifted to image right\n",
        "#             batch_cur.append(cur_img)\n",
        "#             # if i<3 and j<3:\n",
        "#             #   pert_image_numpy = cur_img.squeeze()\n",
        "#             #   print(pert_image_numpy.shape)\n",
        "#             #   plt.figure()\n",
        "#             #   plt.imshow(pert_image_numpy.transpose(1, 2, 0))\n",
        "#             #   #plt.title(label_pert)\n",
        "#             #   plt.show()\n",
        "#             #\n",
        "#             #   image_numpy = inputs[j].detach().squeeze().numpy()\n",
        "#             #   print(image_numpy.shape)\n",
        "#             #   plt.figure()\n",
        "#             #   plt.imshow(image_numpy.transpose(1, 2, 0))\n",
        "#             #   #plt.title(label_pert)\n",
        "#             #   plt.show()\n",
        "#         squeezed_images.append(torch.tensor(np.array(batch_cur)))\n",
        "#     print(torch.stack(squeezed_images).shape)\n",
        "#     final = torch.stack(squeezed_images)\n",
        "#     torch.save(final, 'squeezed_images.pt')\n",
        "#     return final\n",
        "\n",
        "def CreateAttack(x, eps, grad): # fgsm attack\n",
        "    perturbed_x = x + eps*torch.sign(grad)\n",
        "    return perturbed_x\n",
        "\n",
        "\n",
        "def Checker(model, xLoader, eps):\n",
        "    model.eval()\n",
        "    perturbed_images = []\n",
        "    correct_n, correct, total =0,0,0\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    for i, (image, labels) in enumerate(xLoader):\n",
        "        if device==torch.device('cuda'):\n",
        "            image, labels = image.cuda(), labels.cuda()\n",
        "        image.requires_grad = True\n",
        "        output = model(image)\n",
        "        loss= loss_fn(output, labels)\n",
        "        loss.backward()\n",
        "        grad = image.grad.data # getting image gradient\n",
        "        perturbed_x = CreateAttack(image, eps, grad)\n",
        "        output_adv = model(perturbed_x.to(device)) # applying model on perturbed image to get prediction\n",
        "        #print(\"model output adversary output in checker: \",  output_adv)\n",
        "        predictions = torch.argmax(output_adv, dim=1)\n",
        "        correct = torch.sum(predictions == labels).type(torch.float32).item() #see if image was classified wrong\n",
        "        total += labels.shape[0]\n",
        "        if (correct != 1):\n",
        "            perturbed_images.append(perturbed_x)  # perturbed classification correct, add to list to present later\n",
        "        if(correct==1):\n",
        "            correct_n+=1\n",
        "\n",
        "    acc = (correct_n / total)\n",
        "    print('Accuracy: in test', acc) # accuracy on perturbed images\n",
        "    return acc, perturbed_images\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    global device\n",
        "    device = torch.device('cpu')\n",
        "    # check if cuda is available\n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    if train_on_gpu:\n",
        "        device = torch.device('cuda')\n",
        "        print(\"CUDA available. Training on GPU\")\n",
        "    else:\n",
        "        print(\"CUDA is not available. Training on CPU\")\n",
        "\n",
        "    train_loader, val_loader, test_loader, test_for_adv, train_for_adv = load_dataset()\n",
        "    batch_size = 64\n",
        "    max_epochs = 80  # number of steps between evaluations\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    # step 1 - initialize and train model\n",
        "      #Model\n",
        "    PATH = './model.pth'\n",
        "    model = CNN_model().to(device)  # with dropout, batch, without FC layers\n",
        "    # model.load_state_dict(torch.load(PATH, map_location=torch.device(device)))\n",
        "\n",
        "    summary(model, input_size=(3, 32, 32))\n",
        "    print(model)\n",
        "\n",
        "    model = train_data(model, 100, 0.0001, loss_fn, train_loader, val_loader, PATH, feature_squeezing=False)\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    print('\\n\\nFinished Training model\\n\\n')\n",
        "\n",
        "\n",
        "      #Test\n",
        "    print(\"\\n\\nbase model for CIFAR-10 performence:\")\n",
        "    test_data(model, test_loader)\n",
        "\n",
        "    # step 2: adv attack - deep fool on clean data\n",
        "    attacked_deepfool = calling_deepfool(model, test_loader, accflag=True)\n",
        "    print(\"\\n\\ndeepfool attack performence:\")\n",
        "    test_data(model, attacked_deepfool)\n",
        "\n",
        "    # adv_images = batched_deepfool_train(model, train_loader)\n",
        "    # print('\\n\\nFinished creating batched images\\n\\n')\n",
        "\n",
        "    # step 3: adv training and then retest deepfool\n",
        "      #Model\n",
        "    PATH_ADV_deepfool = './model_train_adv_deepfool.pth'\n",
        "    # model_adv_train = CNN_model().to(device)\n",
        "    # model_adv_train.load_state_dict(torch.load(PATH_ADV_deepfool, map_location=torch.device(device)))\n",
        "        #Adversarial loaders\n",
        "    print(\"\\n\\nstarting adversarial train loader\")\n",
        "    adver_trainLoader=calling_deepfool(model, train_loader, accflag=False)\n",
        "    # adver_trainLoader=xLoader_deepfool(model, train_loader)\n",
        "\n",
        "    print(\"\\n\\nstarting adversarial val  loader\")\n",
        "    adver_valLoader=calling_deepfool(model, val_loader, accflag=False)\n",
        "    # adver_valLoader=xLoader_deepfool(model, val_loader)\n",
        "\n",
        "    model_adv_train = train_data(model, 100, 0.0001, loss_fn, adver_trainLoader, adver_valLoader, PATH_ADV_deepfool,feature_squeezing=False)\n",
        "    # model_adv_train = adversarial_train(model, epochs, 0.0001, loss_fn, train_loader, val_loader, PATH_ADV_deepfool, tensor_adv_images\n",
        "   \n",
        "      #Tests\n",
        "    print(\"\\n\\nadversarial training on tast loader:\")\n",
        "    test_data(model_adv_train, test_loader)\n",
        "    \n",
        "    print(\"\\n\\nadversarial training on carpeted (deepfool) tast loader:\")\n",
        "    test_data(model_adv_train, attacked_deepfool)\n",
        "\n",
        "    # # step 4: fgsm adversarial training\n",
        "      #Model\n",
        "    # PATH_ADV_fgsm = './model_train_adv_fgsm.pth'\n",
        "    # model_adv_train_fg = CNN_model().to(device)\n",
        "    # model_adv_train_fg.load_state_dict(torch.load(PATH_ADV_fgsm))\n",
        "\n",
        "    # epochs = 100  # was 100\n",
        "    # #model_adv_train_fg = adversarial_train(model, epochs, 0.0001, loss_fn, train_loader, val_loader, PATH_ADV_fgsm)\n",
        "\n",
        "      #Test\n",
        "    # Checker(model_adv_train_fg, test_for_adv, 0.1)\n",
        "\n",
        "\n",
        "\n",
        "    # step 5: apply feauture squeezing defense and then test deepfool attack\n",
        "      #Model\n",
        "    PATH_SQUEEZED = './model_squeezed.pth'\n",
        "    # model_squeezed_train = CNN_model().to(device)\n",
        "    # model_squeezed_train.load_state_dict(torch.load(PATH_SQUEEZED, map_location=torch.device(device)))\n",
        "\n",
        "    model_squeezed_train = train_data(model, 100, 0.0001, loss_fn, train_loader, val_loader,PATH_SQUEEZED, feature_squeezing=True)  # squeezed_images instead train loader\n",
        "   \n",
        "    \n",
        "      #Tests\n",
        "    print(\"\\n\\nfeature squeezing on tast loader:\")\n",
        "    test_data(model_squeezed_train, test_loader)\n",
        "\n",
        "    print(\"\\n\\nfeature squeezing on carpeted (deepfool) tast loader:\")\n",
        "    test_data(model_squeezed_train, attacked_deepfool)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KiON9x812dW3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of DL_project-adversary_attacks.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}