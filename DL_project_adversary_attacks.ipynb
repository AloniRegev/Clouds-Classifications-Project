{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_project-adversary_attacks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIy6nyyMCkk0GdPCL+JhNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AloniRegev/Defense-Against-Adversarial-Examples-in-NN/blob/main/DL_project_adversary_attacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9XA7jz320MgQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch import optim\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data\n",
        "from torchsummary import summary\n",
        "\n",
        "# for adversary\n",
        "import copy\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    transform_train = transforms.Compose([\n",
        "        #agmentation below\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        #regular normalization\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ])\n",
        "\n",
        "    # Normalize the test set same as training set without augmentation\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
        "    ])\n",
        "\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    print(f' trainset: {trainset}')\n",
        "    #print(f' trainset shape: {trainset.size()}')\n",
        "\n",
        "    ## script to find mean\n",
        "    # data = trainset.data / 255  # data is numpy array\n",
        "    #\n",
        "    # mean = data.mean(axis=(0, 1, 2))\n",
        "    # std = data.std(axis=(0, 1, 2))\n",
        "    # print(f\"Mean : {mean}   STD: {std}\")  # Mean : [0.491 0.482 0.446]   STD: [0.247 0.243 0.261]\n",
        "\n",
        "    cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)#transform_test\n",
        "    cifar_trainset, cifar_valset = data.random_split(trainset, [int(len(trainset) * 0.8), int(len(trainset) * 0.2)])  # split the trainset to trainset and validation set in 80%-20% retio\n",
        "\n",
        "    print('train set len', len(cifar_trainset))\n",
        "    print('validation set len', len(cifar_valset))\n",
        "    print('test set len', len(cifar_testset))\n",
        "\n",
        "    number_workers =0\n",
        "    if device==torch.device('cuda'):\n",
        "        number_workers = 2\n",
        "    train_loader = data.DataLoader(cifar_trainset, shuffle=True, batch_size=64, num_workers=number_workers)\n",
        "    val_loader = data.DataLoader(cifar_valset, shuffle=False, batch_size=64, num_workers=number_workers) #TODO: changed shuffle see if helps\n",
        "    test_loader = data.DataLoader(cifar_testset, shuffle=False, batch_size=64, num_workers=number_workers)\n",
        "\n",
        "\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "# model3:  with dropout, with batch, without fc layers\n",
        "\n",
        "#model3\n",
        "class CNN_model3(nn.Module): #TODO: fix so I get correct dimensions of output\n",
        "    def __init__(self):\n",
        "        super(CNN_model3, self).__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=10, kernel_size=1),\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # conv layers\n",
        "        features = self.feature_extractor(x)\n",
        "        #print(\"features shape:\", features.shape)\n",
        "\n",
        "        # final non fully connected\n",
        "        class_scores = self.classifier(features)\n",
        "        #print(\"class_scores shape:\", class_scores.shape)\n",
        "        class_scores = torch.reshape(class_scores, (class_scores.size(dim=0), class_scores.size(dim=1)))\n",
        "        #print(\"class_scores shape:\", class_scores.shape)\n",
        "\n",
        "        return class_scores\n",
        "\n",
        "\n",
        "\n",
        "# Train\n",
        "def train_data(model, epochs, learning_rate, loss_function, train_loader, valid_loader, patience=4):\n",
        "    loss_arr = []\n",
        "    avg_train_loss_arr, avg_val_loss_arr = [], []\n",
        "    train_acc_arr, val_acc_arr = [], []\n",
        "    # Early stopping  parameters\n",
        "    last_loss = 100 #initializing max loss as high unreachable value\n",
        "    trigger_times = 0\n",
        "    PATH = './checkpoint'\n",
        "    total, correct = 0.0, 0.0\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.00012)\n",
        "\n",
        "    dataiter = iter(train_loader)\n",
        "    images, labels = dataiter.next()\n",
        "    print(type(images))\n",
        "    print(images.shape)\n",
        "    print(labels.shape)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train() #defining we're training so can use dropout, batch norm\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "            if device==torch.device('cuda'):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward and backward propagation\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss_arr.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Show progress\n",
        "            if i % 100 == 0 or i == len(train_loader):\n",
        "                #print('[{}/{}, {}/{}] loss: {:.8}'.format(epoch, epochs, i, len(train_loader), loss.item()))\n",
        "                print(\"Iteration: {0} | Loss: {1} | index {2} \".format(epoch, loss.item(),i))\n",
        "\n",
        "            total += inputs.shape[0]\n",
        "            predictions = torch.argmax(outputs.data, dim=1)\n",
        "            correct += torch.sum(predictions == labels).type(torch.float32)\n",
        "\n",
        "        #print(\"total is: {0}, len(train_loader): {1}, correct pred num is: {2}\".format(total, len(train_loader), correct))\n",
        "        train_acc = (correct / total)\n",
        "        print('Accuracy: in train', train_acc)\n",
        "        train_acc_arr.append(train_acc.item())\n",
        "\n",
        "        plot_graph(loss_arr, \"generic network training loss\")\n",
        "        avg_train_loss_arr.append(np.mean(loss_arr))\n",
        "        # Early stopping\n",
        "        current_loss, avg_val_loss , val_acc = validation_data(model, valid_loader)\n",
        "        print('The Current Loss by validation data:', current_loss)\n",
        "        avg_val_loss_arr.append(avg_val_loss.item())\n",
        "        val_acc_arr.append(val_acc.item())\n",
        "\n",
        "        if current_loss > last_loss:\n",
        "            trigger_times += 1\n",
        "            #print('Trigger Times:', trigger_times)\n",
        "\n",
        "            if trigger_times >= patience:\n",
        "                print('Early stopping!\\nStart to test process.')\n",
        "                break #exit loop, print data\n",
        "\n",
        "        else:\n",
        "            #print('trigger times did not increase:' , trigger_times)\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            trigger_times = 0\n",
        "\n",
        "        last_loss = current_loss\n",
        "\n",
        "    model.load_state_dict(torch.load(PATH))\n",
        "    plot_graph(loss_arr, \"generic network training loss\")\n",
        "\n",
        "    plt.plot(avg_train_loss_arr, label='train loss')\n",
        "    # Plot another line on the same chart/graph\n",
        "    plt.plot(avg_val_loss_arr, label='val loss')\n",
        "    plt.title(\"avg train loss vs avg validation loss\")\n",
        "    plt.legend()\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('loss')\n",
        "    # plt.savefig('./outputs_q1/avg_train_loss_vs_avg_validation_loss.png')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(train_acc_arr, label='train accuracy')\n",
        "    # Plot another line on the same chart/graph\n",
        "    plt.plot(val_acc_arr, label='validation accuracy')\n",
        "    plt.title(\"avg train acc vs avg validation acc\")\n",
        "    plt.legend()\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel('accuracy')\n",
        "    # plt.savefig('./outputs_q1/avg_train_acc_vs_avg_validation_acc.png')\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def plot_graph(list, title):\n",
        "    plt.plot(list)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def validation_data(model, valid_loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_total = 0.0\n",
        "    loss_arr = []\n",
        "\n",
        "    # iterate over test data\n",
        "    with torch.no_grad(): #disable gradients because we only run on test data\n",
        "        for (data, labels) in valid_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device==torch.device('cuda'):\n",
        "                data, labels = data.cuda(), labels.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss_valid = loss_fn(output, labels)\n",
        "            loss_arr.append(loss_valid.item())\n",
        "            loss_total += loss_valid.item()\n",
        "\n",
        "            total += data.shape[0]\n",
        "            predictions = torch.argmax(output.data, dim=1)\n",
        "            correct+= torch.sum(predictions==labels).type(torch.float32)\n",
        "\n",
        "    #plot_graph(loss_arr, \"generic network valid loss\")\n",
        "    acc = (correct / total)\n",
        "    print('Accuracy: in validation', acc)\n",
        "\n",
        "    return (loss_total / len(valid_loader)), np.mean(loss_arr), acc\n",
        "\n",
        "\n",
        "def test_data(model, test_loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    loss_arr = []\n",
        "\n",
        "    # iterate over test data\n",
        "    with torch.no_grad(): #disable gradients because we only run on test data\n",
        "        for (data, labels) in test_loader:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if device==torch.device('cuda'):\n",
        "                data, labels = data.cuda(), labels.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss_test = loss_fn(output, labels)\n",
        "            loss_arr.append(loss_test.item())\n",
        "\n",
        "            total += data.shape[0]\n",
        "            predictions = torch.argmax(output.data, dim=1)\n",
        "            correct+= torch.sum(predictions==labels).type(torch.float32)\n",
        "\n",
        "    plot_graph(loss_arr, \"generic network test loss\")\n",
        "\n",
        "    print('Accuracy: in test', (correct / total))\n",
        "\n",
        "\n",
        "def deepfool(image, net, num_classes=10, overshoot=0.02, max_iter=10):\n",
        "\n",
        "    print('in deepfool before first forward')\n",
        "    image_torch = torch.tensor(image, device=device)\n",
        "    f_image = net.forward(image_torch)\n",
        "    #f_image = net.forward(image_torch).data.numpy().flatten()\n",
        "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
        "\n",
        "    print('after first')\n",
        "\n",
        "    I = I[0:num_classes]\n",
        "    label = I[0]\n",
        "\n",
        "    input_shape = image.detach().numpy().shape\n",
        "    pert_image = copy.deepcopy(image)\n",
        "    w = np.zeros(input_shape)\n",
        "    r_tot = np.zeros(input_shape)\n",
        "\n",
        "    loop_i = 0\n",
        "\n",
        "    x = torch.tensor(pert_image[None, :],requires_grad=True)\n",
        "    \n",
        "    fs = net.forward(x[0])\n",
        "    print('after second forward')\n",
        "    fs_list = [fs[0,I[k]] for k in range(num_classes)]\n",
        "    k_i = label\n",
        "\n",
        "    while k_i == label and loop_i < max_iter:\n",
        "\n",
        "        pert = np.inf\n",
        "        fs[0, I[0]].backward(retain_graph=True)\n",
        "        grad_orig = x.grad.data.numpy().copy()\n",
        "\n",
        "        for k in range(1, num_classes):\n",
        "            \n",
        "            #x.zero_grad()\n",
        "            \n",
        "            fs[0, I[k]].backward(retain_graph=True)\n",
        "            cur_grad = x.grad.data.numpy().copy()\n",
        "\n",
        "            # set new w_k and new f_k\n",
        "            w_k = cur_grad - grad_orig\n",
        "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.numpy()\n",
        "\n",
        "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
        "\n",
        "            # determine which w_k to use\n",
        "            if pert_k < pert:\n",
        "                pert = pert_k\n",
        "                w = w_k\n",
        "\n",
        "        # compute r_i and r_tot\n",
        "        # Added 1e-4 for numerical stability\n",
        "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
        "        r_tot = np.float32(r_tot + r_i)\n",
        "\n",
        "        pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
        "\n",
        "        x = torch.tensor(pert_image, requires_grad=True)\n",
        "        fs = net.forward(x[0])\n",
        "        k_i = np.argmax(fs.data.numpy().flatten())\n",
        "\n",
        "        loop_i += 1\n",
        "\n",
        "    r_tot = (1+overshoot)*r_tot\n",
        "\n",
        "    return r_tot, loop_i, label, k_i, pert_image\n",
        "\n",
        "\n",
        "def deepfool(test_images, net, num_classes=10, overshoot=0.02, max_iter=10):\n",
        "\n",
        "    print('in deepfool before first forward')\n",
        "    image_torch = torch.tensor(image, device=device)\n",
        "    f_image = net.forward(image_torch)\n",
        "    #f_image = net.forward(image_torch).data.numpy().flatten()\n",
        "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
        "\n",
        "    print('after first')\n",
        "\n",
        "    I = I[0:num_classes]\n",
        "    label = I[0]\n",
        "\n",
        "    input_shape = image.detach().numpy().shape\n",
        "    pert_image = copy.deepcopy(image)\n",
        "    w = np.zeros(input_shape)\n",
        "    r_tot = np.zeros(input_shape)\n",
        "\n",
        "    loop_i = 0\n",
        "\n",
        "    x = torch.tensor(pert_image[None, :],requires_grad=True)\n",
        "    \n",
        "    fs = net.forward(x[0])\n",
        "    print('after second forward')\n",
        "    fs_list = [fs[0,I[k]] for k in range(num_classes)]\n",
        "    k_i = label\n",
        "\n",
        "    while k_i == label and loop_i < max_iter:\n",
        "\n",
        "        pert = np.inf\n",
        "        fs[0, I[0]].backward(retain_graph=True)\n",
        "        grad_orig = x.grad.data.numpy().copy()\n",
        "\n",
        "        for k in range(1, num_classes):\n",
        "            \n",
        "            #x.zero_grad()\n",
        "            \n",
        "            fs[0, I[k]].backward(retain_graph=True)\n",
        "            cur_grad = x.grad.data.numpy().copy()\n",
        "\n",
        "            # set new w_k and new f_k\n",
        "            w_k = cur_grad - grad_orig\n",
        "            f_k = (fs[0, I[k]] - fs[0, I[0]]).data.numpy()\n",
        "\n",
        "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
        "\n",
        "            # determine which w_k to use\n",
        "            if pert_k < pert:\n",
        "                pert = pert_k\n",
        "                w = w_k\n",
        "\n",
        "        # compute r_i and r_tot\n",
        "        # Added 1e-4 for numerical stability\n",
        "        r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
        "        r_tot = np.float32(r_tot + r_i)\n",
        "\n",
        "        pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
        "\n",
        "        x = torch.tensor(pert_image, requires_grad=True)\n",
        "        fs = net.forward(x[0])\n",
        "        k_i = np.argmax(fs.data.numpy().flatten())\n",
        "\n",
        "        loop_i += 1\n",
        "\n",
        "    r_tot = (1+overshoot)*r_tot\n",
        "\n",
        "    return r_tot, loop_i, label, k_i, pert_image\n",
        "\n",
        "\n",
        "def calling_deepfool(net):\n",
        "\n",
        "  # Switch to evaluation mode\n",
        "  net.eval()\n",
        "\n",
        "  im_orig = Image.open('./DeepFool/test_im1.jpg')\n",
        "\n",
        "  im = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      ])(im_orig)\n",
        "\n",
        "  img = torch.tensor(im[None,:,:,:],requires_grad =True)\n",
        "\n",
        "  r, loop_i, label_orig, label_pert, pert_image = deepfool(img, net,max_iter=50)\n",
        "\n",
        "  labels = open(('./DeepFool/synset_words.txt'), 'r').read().split('\\n')\n",
        "\n",
        "  str_label_orig = labels[np.int(label_orig)].split(',')[0]\n",
        "  str_label_pert = labels[np.int(label_pert)].split(',')[0]\n",
        "\n",
        "  print(\"Original label = \", str_label_orig)\n",
        "  print(\"Perturbed label = \", str_label_pert)\n",
        "\n",
        "  pert_image_numpy = pert_image.detach().squeeze().numpy()\n",
        "  print(pert_image_numpy.shape)\n",
        "  plt.figure()\n",
        "  plt.imshow(pert_image_numpy.transpose(1,2,0))\n",
        "  plt.title(str_label_pert)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(im_orig)\n",
        "  plt.title(str_label_orig)\n",
        "  plt.show()\n",
        "\n",
        "  r_new = r.squeeze()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(r_new.transpose(1,2,0))\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    global device\n",
        "    device = torch.device('cpu')\n",
        "    # check if cuda is available\n",
        "    train_on_gpu = torch.cuda.is_available()\n",
        "    if train_on_gpu:\n",
        "        device = torch.device('cuda')\n",
        "        print(\"CUDA available. Training on GPU\")\n",
        "    else:\n",
        "        print(\"CUDA is not available. Training on CPU\")\n",
        "\n",
        "    train_loader, val_loader, test_loader = load_dataset()\n",
        "    batch_size = 64\n",
        "    max_epochs = 80  # number of steps between evaluations\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    model3 = CNN_model3().to(device)  # with dropout, batch, without FC layers\n",
        "    summary(model3, input_size=(3, 32,32))\n",
        "    print(model3)torch.save(model.state_dict(), PATH)\n",
        "    model3 = train_data(model3, 100, 0.0001, loss_fn, train_loader, val_loader)\n",
        "\n",
        "    #torch.save(model3.state_dict(), PATH)\n",
        "    # PATH = './checkpoint'\n",
        "    # model3.load_state_dict(torch.load(PATH))\n",
        "    test_data(model3, test_loader)\n",
        "    print('\\n\\nFinished Training model3\\n\\n')\n",
        "\n",
        "    #calling_deepfool(model3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "dmu0PDC0zBqd",
        "outputId": "277ba0e7-14df-487d-cd3b-a6eb4fde07d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available. Training on GPU\n",
            "Files already downloaded and verified\n",
            " trainset: Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomCrop(size=(32, 32), padding=4)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
            "           )\n",
            "Files already downloaded and verified\n",
            "train set len 40000\n",
            "validation set len 10000\n",
            "test set len 10000\n",
            "\n",
            "\n",
            "Finished Training model3\n",
            "\n",
            "\n",
            "in deepfool before first forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:369: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:292: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3eccd0ff95d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\nFinished Training model3\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0mcalling_deepfool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3eccd0ff95d2>\u001b[0m in \u001b[0;36mcalling_deepfool\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m   \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_pert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpert_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepfool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./DeepFool/synset_words.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3eccd0ff95d2>\u001b[0m in \u001b[0;36mdeepfool\u001b[0;34m(image, net, num_classes, overshoot, max_iter)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'in deepfool before first forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mimage_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mf_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;31m#f_image = net.forward(image_torch).data.numpy().flatten()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3eccd0ff95d2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mclass_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m#print(\"class_scores shape:\", class_scores.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mclass_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclass_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m#print(\"class_scores shape:\", class_scores.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 10]' is invalid for input of size 34810"
          ]
        }
      ]
    }
  ]
}