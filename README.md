# Defense Against Adversarial Examples in NN
Final project in a Deep Learning course at the University of Haifa. 

## Objective:
Protection against "Deep Fool" adversarial examples through "Adversarial training" and "Feature squeezing" in the form of median smoothing. Each one done separately against the given attack.

## Run me:

## Dataset:
`CIFAR-10` - Collection of 60,000 32x32 color images in 10 different classes.
* Given by `Torchvision` library in `PyTorch` project.

## Architecture:
* Attack: Deep Fool
* Defenses: Adversarial training, feature squeezing in the form of median smoothing. Each one done separately against the given attack
* 
## Testing:

## Results:

### Authors: 
* [Neta Oren](https://github.com/n242)
* [Regev Aloni](https://github.com/AloniRegev)
